{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Лабораторная работа № 1 \n",
    "## Выполнение разведочного анализа больших данных с использованием фреймворка Apache Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Часть 1\n",
    "\n",
    "В данной части работы рассмотрены:\n",
    "* загрузка данных из HDFS;\n",
    "* базовые преобразования данных;\n",
    "* загрузка преобразованных данных в таблицу `Apache Airflow`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подключим необходимые библиотеки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pyspark.sql import SparkSession, DataFrame\n",
    "from pyspark import SparkConf\n",
    "from pyspark.sql.functions import (\n",
    "    regexp_replace,\n",
    "    regexp_extract_all,\n",
    "    col,\n",
    "    lit\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сформируем объект конфигурации для `Apache Spark`, указав необходимые параметры."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_spark_configuration() -> SparkConf:\n",
    "    \"\"\"\n",
    "    Создает и конфигурирует экземпляр SparkConf для приложения Spark.\n",
    "\n",
    "    Returns:\n",
    "        SparkConf: Настроенный экземпляр SparkConf.\n",
    "    \"\"\"\n",
    "    # Получаем имя пользователя\n",
    "    user_name = os.getenv(\"USER\")\n",
    "    \n",
    "    conf = SparkConf()\n",
    "    conf.setAppName(\"lab 1 Test\")\n",
    "    conf.setMaster(\"yarn\")\n",
    "    conf.set(\"spark.submit.deployMode\", \"client\")\n",
    "    conf.set(\"spark.executor.memory\", \"12g\")\n",
    "    conf.set(\"spark.executor.cores\", \"8\")\n",
    "    conf.set(\"spark.executor.instances\", \"2\")\n",
    "    conf.set(\"spark.driver.memory\", \"4g\")\n",
    "    conf.set(\"spark.driver.cores\", \"2\")\n",
    "    conf.set(\"spark.jars.packages\", \"org.apache.iceberg:iceberg-spark-runtime-3.5_2.12:1.6.0\")\n",
    "    conf.set(\"spark.sql.extensions\", \"org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions\")\n",
    "    conf.set(\"spark.sql.catalog.spark_catalog\", \"org.apache.iceberg.spark.SparkCatalog\")\n",
    "    conf.set(\"spark.sql.catalog.spark_catalog.type\", \"hadoop\")\n",
    "    conf.set(\"spark.sql.catalog.spark_catalog.warehouse\", f\"hdfs:///user/{user_name}/warehouse\")\n",
    "    conf.set(\"spark.sql.catalog.spark_catalog.io-impl\", \"org.apache.iceberg.hadoop.HadoopFileIO\")\n",
    "\n",
    "    return conf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создаём сам объект конфигурации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = create_spark_configuration()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создаём и выводим на экран сессию `Apache Spark`. В процессе создания сессии происходит подключение к кластеру `Apache Hadoop`, что может занять некоторое время."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/opt/spark-3.5.2-bin-hadoop3/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /home/user0/.ivy2/cache\n",
      "The jars for the packages stored in: /home/user0/.ivy2/jars\n",
      "org.apache.iceberg#iceberg-spark-runtime-3.5_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-badb9122-c6d1-4b7d-bb9a-0f575197b402;1.0\n",
      "\tconfs: [default]\n",
      "\tfound org.apache.iceberg#iceberg-spark-runtime-3.5_2.12;1.6.0 in central\n",
      ":: resolution report :: resolve 627ms :: artifacts dl 24ms\n",
      "\t:: modules in use:\n",
      "\torg.apache.iceberg#iceberg-spark-runtime-3.5_2.12;1.6.0 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   1   |   0   |   0   |   0   ||   1   |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-badb9122-c6d1-4b7d-bb9a-0f575197b402\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 1 already retrieved (0kB/31ms)\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/11/11 15:45:35 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "24/11/11 15:45:41 WARN Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.\n",
      "24/11/11 15:46:02 WARN Client: Same path resource file:///home/user0/.ivy2/jars/org.apache.iceberg_iceberg-spark-runtime-3.5_2.12-1.6.0.jar added multiple times to distributed cache.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://node32.cluster:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>yarn</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>lab 1 Test</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f5a1fa802d0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark = SparkSession.builder.config(conf=conf).getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для исследования будем использовать датасет `NYC Yellow Taxi Trip Data`, расположенный на платформе `Kaggle` по адресу \n",
    "https://www.kaggle.com/datasets/elemento/nyc-yellow-taxi-trip-data?select=yellow_tripdata_2016-03.csv\n",
    "Датасет включает в себя информацию о поездках на такси.\n",
    "\n",
    "Данный датасет уже загружен в `HDFS` по адресу: `hdfs:///user/user0/gysynin_dmitry_data/yellow_tripdata_2016-03.csv`\n",
    "\n",
    "Указываем путь в `HDFS` для файла с данными."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = \"hdfs:///datasets/used_cars_data.csv\"\n",
    "# hadoop fs -copyFromLocal /home/user0/gysynin_dmitry/SOBD/2024/lab1/datasets/yellow_tripdata_2015-01.csv /user/user0/gysynin_dmitry_data/\n",
    "path = \"hdfs:///user/user0/gysynin_dmitry_data/yellow_tripdata_2015-01.csv\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заполняем датафрейм данными из файла."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = (spark.read.format(\"csv\")\n",
    "      .option(\"header\", \"true\")\n",
    "      # .option(\"multiLine\", \"true\")\n",
    "      .option(\"separator\", \",\")\n",
    "      .load(path)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выводим фрагмент датафрейма на экран."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+---------------------+---------------+-------------+-------------------+------------------+----------+------------------+-------------------+------------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+\n",
      "|VendorID|tpep_pickup_datetime|tpep_dropoff_datetime|passenger_count|trip_distance|   pickup_longitude|   pickup_latitude|RateCodeID|store_and_fwd_flag|  dropoff_longitude|  dropoff_latitude|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|\n",
      "+--------+--------------------+---------------------+---------------+-------------+-------------------+------------------+----------+------------------+-------------------+------------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+\n",
      "|       2| 2015-01-15 19:05:39|  2015-01-15 19:23:42|              1|         1.59|   -73.993896484375|40.750110626220703|         1|                 N|-73.974784851074219|40.750617980957031|           1|         12|    1|    0.5|      3.25|           0|                  0.3|       17.05|\n",
      "|       1| 2015-01-10 20:33:38|  2015-01-10 20:53:28|              1|         3.30| -74.00164794921875|  40.7242431640625|         1|                 N|-73.994415283203125|40.759109497070313|           1|       14.5|  0.5|    0.5|         2|           0|                  0.3|        17.8|\n",
      "|       1| 2015-01-10 20:33:38|  2015-01-10 20:43:41|              1|         1.80|-73.963340759277344|40.802787780761719|         1|                 N|-73.951820373535156|40.824413299560547|           2|        9.5|  0.5|    0.5|         0|           0|                  0.3|        10.8|\n",
      "|       1| 2015-01-10 20:33:39|  2015-01-10 20:35:31|              1|          .50|-74.009086608886719|40.713817596435547|         1|                 N|-74.004325866699219|40.719985961914063|           2|        3.5|  0.5|    0.5|         0|           0|                  0.3|         4.8|\n",
      "|       1| 2015-01-10 20:33:39|  2015-01-10 20:52:58|              1|         3.00|-73.971176147460938|40.762428283691406|         1|                 N|-74.004180908203125|40.742652893066406|           2|         15|  0.5|    0.5|         0|           0|                  0.3|        16.3|\n",
      "|       1| 2015-01-10 20:33:39|  2015-01-10 20:53:52|              1|         9.00|-73.874374389648438|  40.7740478515625|         1|                 N|-73.986976623535156|40.758193969726563|           1|         27|  0.5|    0.5|       6.7|        5.33|                  0.3|       40.33|\n",
      "|       1| 2015-01-10 20:33:39|  2015-01-10 20:58:31|              1|         2.20|  -73.9832763671875|40.726009368896484|         1|                 N|-73.992469787597656|  40.7496337890625|           2|         14|  0.5|    0.5|         0|           0|                  0.3|        15.3|\n",
      "|       1| 2015-01-10 20:33:39|  2015-01-10 20:42:20|              3|          .80|-74.002662658691406|40.734142303466797|         1|                 N|-73.995010375976563|40.726325988769531|           1|          7|  0.5|    0.5|      1.66|           0|                  0.3|        9.96|\n",
      "|       1| 2015-01-10 20:33:39|  2015-01-10 21:11:35|              3|        18.20|-73.783042907714844|40.644355773925781|         2|                 N|-73.987594604492187|40.759357452392578|           2|         52|    0|    0.5|         0|        5.33|                  0.3|       58.13|\n",
      "|       1| 2015-01-10 20:33:40|  2015-01-10 20:40:44|              2|          .90|-73.985588073730469|40.767948150634766|         1|                 N|-73.985916137695313|40.759365081787109|           1|        6.5|  0.5|    0.5|      1.55|           0|                  0.3|        9.35|\n",
      "|       1| 2015-01-10 20:33:40|  2015-01-10 20:41:39|              1|          .90|-73.988616943359375|40.723102569580078|         1|                 N|    -74.00439453125|40.728584289550781|           1|          7|  0.5|    0.5|      1.66|           0|                  0.3|        9.96|\n",
      "|       1| 2015-01-10 20:33:41|  2015-01-10 20:43:26|              1|         1.10|-73.993782043457031|40.751419067382812|         1|                 N|  -73.9674072265625|40.757217407226563|           1|        7.5|  0.5|    0.5|         1|           0|                  0.3|         9.8|\n",
      "|       1| 2015-01-10 20:33:41|  2015-01-10 20:35:23|              1|          .30| -74.00836181640625|40.704376220703125|         1|                 N|-74.009773254394531|40.707725524902344|           2|          3|  0.5|    0.5|         0|           0|                  0.3|         4.3|\n",
      "|       1| 2015-01-10 20:33:41|  2015-01-10 21:03:04|              1|         3.10|-73.973945617675781|40.760448455810547|         1|                 N|-73.997344970703125|40.735210418701172|           1|         19|  0.5|    0.5|         3|           0|                  0.3|        23.3|\n",
      "|       1| 2015-01-10 20:33:41|  2015-01-10 20:39:23|              1|         1.10|-74.006721496582031|40.731777191162109|         1|                 N|-73.995216369628906|40.739894866943359|           2|          6|  0.5|    0.5|         0|           0|                  0.3|         7.3|\n",
      "|       2| 2015-01-15 19:05:39|  2015-01-15 19:32:00|              1|         2.38|-73.976425170898437|40.739810943603516|         1|                 N|-73.983978271484375|40.757888793945313|           1|       16.5|    1|    0.5|      4.38|           0|                  0.3|       22.68|\n",
      "|       2| 2015-01-15 19:05:40|  2015-01-15 19:21:00|              5|         2.83|-73.968704223632812|40.754245758056641|         1|                 N|-73.955123901367188|40.786857604980469|           2|       12.5|    1|    0.5|         0|           0|                  0.3|        14.3|\n",
      "|       2| 2015-01-15 19:05:40|  2015-01-15 19:28:18|              5|         8.33|-73.863059997558594|40.769580841064453|         1|                 N|-73.952713012695312|40.785781860351563|           1|         26|    1|    0.5|      8.08|        5.33|                  0.3|       41.21|\n",
      "|       2| 2015-01-15 19:05:41|  2015-01-15 19:20:36|              1|         2.37|-73.945541381835938|40.779422760009766|         1|                 N|-73.980850219726563|40.786083221435547|           1|       11.5|    1|    0.5|         0|           0|                  0.3|        13.3|\n",
      "|       2| 2015-01-15 19:05:41|  2015-01-15 19:20:22|              2|         7.13|-73.874458312988281|40.774009704589844|         1|                 N|-73.952377319335938|40.718589782714844|           1|       21.5|    1|    0.5|       4.5|           0|                  0.3|        27.8|\n",
      "+--------+--------------------+---------------------+---------------+-------------+-------------------+------------------+----------+------------------+-------------------+------------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Очевидно, что в целях сохранения ясности изложения и сокращения расчетного времени имеет смысл рассматривать не все солбцы датасета. Оставим следующие колонки, удалив остальные:\n",
    "\n",
    "\n",
    "| Название столбца  | Расшифровка |\n",
    "| ------------- | ------------- |\n",
    "| VendorID | Код, указывающий на поставщика услуг TPEP, который предоставил запись. 1 - Creative Mobile Technologies 2- VeriFone Inc. |\n",
    "| passenger_count | Количество пассажиров |\n",
    "| trip_distance | Расстояние поездки |\n",
    "| RateCodeID | Окончательный код тарифа, действующий в конце поездки. 1- Стандартный тариф 2- JFK 3- Ньюарк 4- Нассау или Вестчестер 5- Тариф по договоренности 6- Групповая поездка |\n",
    "| store_and_fwd_flag | Этот флаг указывает, хранилась ли запись о поездке в памяти автомобиля перед отправкой поставщику, так называемый «store and forward», поскольку автомобиль не имел соединения с сервером. Y = поездка с сохранением и пересылкой N= не поездка с сохранением и пересылкой |\n",
    "| payment_type | Цифровой код, обозначающий, каким образом пассажир оплатил поездку. 1- Кредитная карта 2- Наличные 3- Без оплаты 4-Спор 5- Неизвестно 6-Анулированная поездка |\n",
    "| fare_amount | Тариф за время и расстояние, рассчитанный счетчиком. |\n",
    "| extra | Различные доплаты и надбавки. В настоящее время сюда входят только сборы в размере 0,50 и 1 доллара в час пик и ночные сборы. |\n",
    "| tip_amount | Сумма чаевых - Это поле автоматически заполняется для чаевых по кредитной карте. Чаевые наличными не учитываются. |\n",
    "| tolls_amount | Общая сумма всех дорожных сборов, оплаченных в поездке. |\n",
    "| total_amount | Общая сумма, взимаемая с пассажиров. Не включает денежные чаевые. |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.select(\n",
    "    \"VendorID\", \"passenger_count\", \"trip_distance\",\n",
    "    \"RateCodeID\", \"store_and_fwd_flag\", \"payment_type\", \n",
    "    \"fare_amount\", \"extra\", \"tip_amount\",\n",
    "    \"tolls_amount\", \"total_amount\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 2:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------------+-------------+----------+------------------+------------+-----------+-----+----------+------------+------------+\n",
      "|VendorID|passenger_count|trip_distance|RateCodeID|store_and_fwd_flag|payment_type|fare_amount|extra|tip_amount|tolls_amount|total_amount|\n",
      "+--------+---------------+-------------+----------+------------------+------------+-----------+-----+----------+------------+------------+\n",
      "|       2|              1|         1.59|         1|                 N|           1|         12|    1|      3.25|           0|       17.05|\n",
      "|       1|              1|         3.30|         1|                 N|           1|       14.5|  0.5|         2|           0|        17.8|\n",
      "|       1|              1|         1.80|         1|                 N|           2|        9.5|  0.5|         0|           0|        10.8|\n",
      "|       1|              1|          .50|         1|                 N|           2|        3.5|  0.5|         0|           0|         4.8|\n",
      "|       1|              1|         3.00|         1|                 N|           2|         15|  0.5|         0|           0|        16.3|\n",
      "|       1|              1|         9.00|         1|                 N|           1|         27|  0.5|       6.7|        5.33|       40.33|\n",
      "|       1|              1|         2.20|         1|                 N|           2|         14|  0.5|         0|           0|        15.3|\n",
      "|       1|              3|          .80|         1|                 N|           1|          7|  0.5|      1.66|           0|        9.96|\n",
      "|       1|              3|        18.20|         2|                 N|           2|         52|    0|         0|        5.33|       58.13|\n",
      "|       1|              2|          .90|         1|                 N|           1|        6.5|  0.5|      1.55|           0|        9.35|\n",
      "|       1|              1|          .90|         1|                 N|           1|          7|  0.5|      1.66|           0|        9.96|\n",
      "|       1|              1|         1.10|         1|                 N|           1|        7.5|  0.5|         1|           0|         9.8|\n",
      "|       1|              1|          .30|         1|                 N|           2|          3|  0.5|         0|           0|         4.3|\n",
      "|       1|              1|         3.10|         1|                 N|           1|         19|  0.5|         3|           0|        23.3|\n",
      "|       1|              1|         1.10|         1|                 N|           2|          6|  0.5|         0|           0|         7.3|\n",
      "|       2|              1|         2.38|         1|                 N|           1|       16.5|    1|      4.38|           0|       22.68|\n",
      "|       2|              5|         2.83|         1|                 N|           2|       12.5|    1|         0|           0|        14.3|\n",
      "|       2|              5|         8.33|         1|                 N|           1|         26|    1|      8.08|        5.33|       41.21|\n",
      "|       2|              1|         2.37|         1|                 N|           1|       11.5|    1|         0|           0|        13.3|\n",
      "|       2|              2|         7.13|         1|                 N|           1|       21.5|    1|       4.5|           0|        27.8|\n",
      "+--------+---------------+-------------+----------+------------------+------------+-----------+-----+----------+------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выведем на экран метаданные датасета."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- VendorID: string (nullable = true)\n",
      " |-- passenger_count: string (nullable = true)\n",
      " |-- trip_distance: string (nullable = true)\n",
      " |-- RateCodeID: string (nullable = true)\n",
      " |-- store_and_fwd_flag: string (nullable = true)\n",
      " |-- payment_type: string (nullable = true)\n",
      " |-- fare_amount: string (nullable = true)\n",
      " |-- extra: string (nullable = true)\n",
      " |-- tip_amount: string (nullable = true)\n",
      " |-- tolls_amount: string (nullable = true)\n",
      " |-- total_amount: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видно, что все столбцы датасета содержат строковый тип данных, что не соответствует ожиданиям. Выполним преобразования типов данных некоторых столбцов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_dataframe(data: DataFrame) -> DataFrame:\n",
    "    \"\"\"\n",
    "    Преобразует столбцы DataFrame в указанные типы данных и\n",
    "    выполняет необходимые преобразования.\n",
    "\n",
    "    Args:\n",
    "        data (DataFrame): Исходный DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: Преобразованный DataFrame.\n",
    "    \"\"\"\n",
    "    # Преобразуем столбцы в соответствующие типы данных\n",
    "    data = data.withColumn(\"VendorID\",\n",
    "                    col(\"VendorID\").cast(\"Integer\"))\n",
    "    data = data.withColumn(\"passenger_count\",\n",
    "                    col(\"passenger_count\").cast(\"Integer\"))\n",
    "    data = data.withColumn(\"RateCodeID\",\n",
    "                    col(\"RateCodeID\").cast(\"Integer\"))\n",
    "    data = data.withColumn(\"payment_type\",\n",
    "                    col(\"payment_type\").cast(\"Integer\"))\n",
    "\n",
    "    data = data.withColumn(\"trip_distance\",\n",
    "                    col(\"trip_distance\").cast(\"Float\"))\n",
    "    data = data.withColumn(\"fare_amount\",\n",
    "                    col(\"fare_amount\").cast(\"Float\"))\n",
    "    data = data.withColumn(\"extra\",\n",
    "                    col(\"extra\").cast(\"Float\"))\n",
    "    data = data.withColumn(\"tip_amount\",\n",
    "                    col(\"tip_amount\").cast(\"Float\"))\n",
    "    data = data.withColumn(\"tolls_amount\",\n",
    "                    col(\"tolls_amount\").cast(\"Float\"))\n",
    "    data = data.withColumn(\"total_amount\",\n",
    "                    col(\"total_amount\").cast(\"Float\"))\n",
    "\n",
    "    data = data.withColumn(\"store_and_fwd_flag\",\n",
    "                    col(\"store_and_fwd_flag\").cast(\"Boolean\"))\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = transform_dataframe(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 3:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------------+-------------+----------+------------------+------------+-----------+-----+----------+------------+------------+\n",
      "|VendorID|passenger_count|trip_distance|RateCodeID|store_and_fwd_flag|payment_type|fare_amount|extra|tip_amount|tolls_amount|total_amount|\n",
      "+--------+---------------+-------------+----------+------------------+------------+-----------+-----+----------+------------+------------+\n",
      "|       2|              1|         1.59|         1|             false|           1|       12.0|  1.0|      3.25|         0.0|       17.05|\n",
      "|       1|              1|          3.3|         1|             false|           1|       14.5|  0.5|       2.0|         0.0|        17.8|\n",
      "|       1|              1|          1.8|         1|             false|           2|        9.5|  0.5|       0.0|         0.0|        10.8|\n",
      "|       1|              1|          0.5|         1|             false|           2|        3.5|  0.5|       0.0|         0.0|         4.8|\n",
      "|       1|              1|          3.0|         1|             false|           2|       15.0|  0.5|       0.0|         0.0|        16.3|\n",
      "|       1|              1|          9.0|         1|             false|           1|       27.0|  0.5|       6.7|        5.33|       40.33|\n",
      "|       1|              1|          2.2|         1|             false|           2|       14.0|  0.5|       0.0|         0.0|        15.3|\n",
      "|       1|              3|          0.8|         1|             false|           1|        7.0|  0.5|      1.66|         0.0|        9.96|\n",
      "|       1|              3|         18.2|         2|             false|           2|       52.0|  0.0|       0.0|        5.33|       58.13|\n",
      "|       1|              2|          0.9|         1|             false|           1|        6.5|  0.5|      1.55|         0.0|        9.35|\n",
      "|       1|              1|          0.9|         1|             false|           1|        7.0|  0.5|      1.66|         0.0|        9.96|\n",
      "|       1|              1|          1.1|         1|             false|           1|        7.5|  0.5|       1.0|         0.0|         9.8|\n",
      "|       1|              1|          0.3|         1|             false|           2|        3.0|  0.5|       0.0|         0.0|         4.3|\n",
      "|       1|              1|          3.1|         1|             false|           1|       19.0|  0.5|       3.0|         0.0|        23.3|\n",
      "|       1|              1|          1.1|         1|             false|           2|        6.0|  0.5|       0.0|         0.0|         7.3|\n",
      "|       2|              1|         2.38|         1|             false|           1|       16.5|  1.0|      4.38|         0.0|       22.68|\n",
      "|       2|              5|         2.83|         1|             false|           2|       12.5|  1.0|       0.0|         0.0|        14.3|\n",
      "|       2|              5|         8.33|         1|             false|           1|       26.0|  1.0|      8.08|        5.33|       41.21|\n",
      "|       2|              1|         2.37|         1|             false|           1|       11.5|  1.0|       0.0|         0.0|        13.3|\n",
      "|       2|              2|         7.13|         1|             false|           1|       21.5|  1.0|       4.5|         0.0|        27.8|\n",
      "+--------+---------------+-------------+----------+------------------+------------+-----------+-----+----------+------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- VendorID: integer (nullable = true)\n",
      " |-- passenger_count: integer (nullable = true)\n",
      " |-- trip_distance: float (nullable = true)\n",
      " |-- RateCodeID: integer (nullable = true)\n",
      " |-- store_and_fwd_flag: boolean (nullable = true)\n",
      " |-- payment_type: integer (nullable = true)\n",
      " |-- fare_amount: float (nullable = true)\n",
      " |-- extra: float (nullable = true)\n",
      " |-- tip_amount: float (nullable = true)\n",
      " |-- tolls_amount: float (nullable = true)\n",
      " |-- total_amount: float (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видно, что теперь столбцы датафрейма содержат значения корректных типов.\n",
    "\n",
    "Полученный датафрейм сохраним для дальнейшего использования. Сохранение выполним в таблицу `Apache Iceberg`. \n",
    "\n",
    "`Apache Iceberg` — это поддерживающий высокую производительность табличный формат для больших данных.\n",
    "\n",
    "Сначала создадим базу данных, в которой будет расположена таблица. Во избежание путаницы, **каждую таблицу следует называть с использованием фамилии студента**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "database_name = \"gysynin_dmitry_database\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим инструкцию SQL для добавления базы данных в каталог `Apache Spark`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_database_sql = f\"\"\"\n",
    "CREATE DATABASE IF NOT EXISTS spark_catalog.{database_name}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(create_database_sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Установим созданную базу данных как текущую."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.catalog.setCurrentDatabase(database_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И, наконец, записываем преобразованный датафрейм в таблицу `sobd_lab1_table_gysynin`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Сохранение DataFrame в виде таблицы\n",
    "df.writeTo(\"sobd_lab1_table_gysynin\").using(\"iceberg\").create()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После успешной записи можно посмотреть, какие таблицы входят в базу данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sobd_lab1_processed_table\n",
      "sobd_lab1_table_gysynin\n"
     ]
    }
   ],
   "source": [
    "for table in spark.catalog.listTables():\n",
    "    print(table.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обратите внимание, что при необходимости созданные базу данных и таблицу можно удалить следующими командами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"DROP TABLE spark_catalog.gysynin_dmitry_database.sobd_lab1_table_gysynin\")\n",
    "spark.sql(\"DROP DATABASE spark_catalog.gysynin_dmitry_database\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После успешной записи таблицы останавливаем сессию `Apache Spark`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "/user/user0/gysynin_dmitry_data/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
