{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Лабораторная работа № 2 \n",
    "## Машинное обучение на больших данных с использованием фреймворка Apache Spark и библиотеки SparkML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Часть 2\n",
    "\n",
    "В данной части работы рассмотрены:\n",
    "* подготовка признаков для рeшения задачи **RandomForestClassifier**;\n",
    "* создание и обучение модели;\n",
    "* оценка качества модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Запуск `Spark`-сессии\n",
    "\n",
    "Подключаем необходимые библиотеки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from pyspark.sql import SparkSession, DataFrame\n",
    "from pyspark import SparkConf\n",
    "from pyspark.ml.feature import VectorAssembler, StringIndexer, Binarizer, Bucketizer\n",
    "from pyspark.ml.functions import vector_to_array\n",
    "from pyspark.ml.classification import GBTClassifier, GBTClassificationModel\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator, CrossValidatorModel, ParamGridBuilder\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import DoubleType, IntegerType\n",
    "from pyspark.sql import Window\n",
    "\n",
    "\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сформируем объект конфигурации для `Apache Spark`, указав необходимые параметры."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_spark_configuration() -> SparkConf:\n",
    "    \"\"\"\n",
    "    Создает и конфигурирует экземпляр SparkConf для приложения Spark.\n",
    "\n",
    "    Returns:\n",
    "        SparkConf: Настроенный экземпляр SparkConf.\n",
    "    \"\"\"\n",
    "    # Получаем имя пользователя\n",
    "    user_name = os.getenv(\"USER\")\n",
    "    \n",
    "    conf = SparkConf()\n",
    "    conf.setAppName(\"lab 2 Test\")\n",
    "    conf.setMaster(\"yarn\")\n",
    "    conf.set(\"spark.submit.deployMode\", \"client\")\n",
    "    conf.set(\"spark.executor.memory\", \"12g\")\n",
    "    conf.set(\"spark.executor.cores\", \"8\")\n",
    "    conf.set(\"spark.executor.instances\", \"2\")\n",
    "    conf.set(\"spark.driver.memory\", \"4g\")\n",
    "    conf.set(\"spark.driver.cores\", \"2\")\n",
    "    conf.set(\"spark.jars.packages\", \"org.apache.iceberg:iceberg-spark-runtime-3.5_2.12:1.6.0\")\n",
    "    conf.set(\"spark.sql.extensions\", \"org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions\")\n",
    "    conf.set(\"spark.sql.catalog.spark_catalog\", \"org.apache.iceberg.spark.SparkCatalog\")\n",
    "    conf.set(\"spark.sql.catalog.spark_catalog.type\", \"hadoop\")\n",
    "    conf.set(\"spark.sql.catalog.spark_catalog.warehouse\", f\"hdfs:///user/{user_name}/warehouse\")\n",
    "    conf.set(\"spark.sql.catalog.spark_catalog.io-impl\", \"org.apache.iceberg.hadoop.HadoopFileIO\")\n",
    "\n",
    "    return conf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создаём сам объект конфигурации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = create_spark_configuration()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создаём и выводим на экран сессию `Apache Spark`. В процессе создания сессии происходит подключение к кластеру `Apache Hadoop`, что может занять некоторое время."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/11/17 20:17:47 WARN Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.\n",
      "24/11/17 20:18:07 WARN Client: Same path resource file:///home/user0/.ivy2/jars/org.apache.iceberg_iceberg-spark-runtime-3.5_2.12-1.6.0.jar added multiple times to distributed cache.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://node32.cluster:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>yarn</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>lab 2 Test</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7ff48938c190>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark = SparkSession.builder.config(conf=conf).getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Загрузка датасета\n",
    "\n",
    "Укажем базу данных, которая была создана в первой лабораторной работе."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "database_name = \"gysynin_dmitry_database\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Установим созданную базу данных как текущую."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.catalog.setCurrentDatabase(database_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Прочитаем таблицу с **предобработанным датасетом** и загрузим её в `Spark Dataframe`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.table(\"sobd_lab1_processed_table\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выведем прочитанную таблицу на экран."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/11/17 20:10:40 WARN YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "24/11/17 20:10:55 WARN YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "[Stage 0:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------------+-------------+----------+------------------+------------+-----------+-----+----------+------------+------------+\n",
      "|VendorID|passenger_count|trip_distance|RateCodeID|store_and_fwd_flag|payment_type|fare_amount|extra|tip_amount|tolls_amount|total_amount|\n",
      "+--------+---------------+-------------+----------+------------------+------------+-----------+-----+----------+------------+------------+\n",
      "|       2|              1|         2.72|         1|             false|           1|       12.5|  0.5|      3.25|         0.0|       17.05|\n",
      "|       2|              1|         1.59|         1|             false|           1|        7.5|  0.5|       1.6|         0.0|        10.4|\n",
      "|       2|              1|          0.9|         1|             false|           1|        6.0|  0.5|       1.0|         0.0|         8.3|\n",
      "|       2|              1|         1.96|         1|             false|           1|        9.5|  0.5|       2.0|         0.0|        12.8|\n",
      "|       2|              3|         8.93|         1|             false|           1|       32.0|  0.5|       0.0|         0.0|        33.3|\n",
      "|       2|              1|         2.45|         1|             false|           1|       13.0|  0.5|       2.7|         0.0|        17.0|\n",
      "|       2|              2|         2.63|         1|             false|           1|       11.5|  0.5|       2.4|         0.0|        15.2|\n",
      "|       2|              1|         1.11|         1|             false|           1|        6.5|  0.5|       1.4|         0.0|         9.2|\n",
      "|       2|              1|          1.7|         1|             false|           1|        8.5|  0.5|       5.0|         0.0|        14.8|\n",
      "|       2|              4|         0.93|         1|             false|           2|        6.5|  0.5|       0.0|         0.0|         7.8|\n",
      "|       2|              1|         1.39|         1|             false|           2|        7.0|  0.5|       0.0|         0.0|         8.3|\n",
      "|       2|              5|          2.0|         1|             false|           2|       10.0|  0.5|       0.0|         0.0|        11.3|\n",
      "|       2|              1|          1.3|         1|             false|           2|        7.0|  0.5|       0.0|         0.0|         8.3|\n",
      "|       2|              1|        17.43|         1|             false|           2|       49.0|  0.5|       0.0|         0.0|        50.3|\n",
      "|       1|              4|          3.5|         1|             false|           2|       15.0|  1.0|       0.0|         0.0|        16.8|\n",
      "|       1|              1|          2.2|         1|             false|           1|       12.5|  1.0|      2.86|         0.0|       17.16|\n",
      "|       1|              1|          0.0|         1|             false|           2|        7.0|  1.0|       0.0|         0.0|         8.8|\n",
      "|       1|              1|          0.6|         1|             false|           1|        4.0|  1.0|      1.16|         0.0|        6.96|\n",
      "|       1|              1|          2.2|         1|             false|           2|       11.5|  1.0|       0.0|         0.0|        13.3|\n",
      "|       1|              1|          1.5|         1|             false|           2|        8.0|  1.0|       0.0|         0.0|         9.8|\n",
      "+--------+---------------+-------------+----------+------------------+------------+-----------+-----+----------+------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вспомним описание столбцов и параметры датасета, проанализированные в первой лабораторной работе.\n",
    "\n",
    "| Название столбца  | Расшифровка |\n",
    "| ------------- | ------------- |\n",
    "| VendorID | Код, указывающий на поставщика услуг TPEP, который предоставил запись. 1 - Creative Mobile Technologies 2- VeriFone Inc. |\n",
    "| passenger_count | Количество пассажиров |\n",
    "| trip_distance | Расстояние поездки |\n",
    "| RateCodeID | Окончательный код тарифа, действующий в конце поездки. 1- Стандартный тариф 2- JFK 3- Ньюарк 4- Нассау или Вестчестер 5- Тариф по договоренности 6- Групповая поездка |\n",
    "| store_and_fwd_flag | Этот флаг указывает, хранилась ли запись о поездке в памяти автомобиля перед отправкой поставщику, так называемый «store and forward», поскольку автомобиль не имел соединения с сервером. Y = поездка с сохранением и пересылкой N= не поездка с сохранением и пересылкой |\n",
    "| payment_type | Цифровой код, обозначающий, каким образом пассажир оплатил поездку. 1- Кредитная карта 2- Наличные 3- Без оплаты 4-Спор 5- Неизвестно 6-Анулированная поездка |\n",
    "| fare_amount | Тариф за время и расстояние, рассчитанный счетчиком. |\n",
    "| extra | Различные доплаты и надбавки. В настоящее время сюда входят только сборы в размере 0,50 и 1 доллара в час пик и ночные сборы. |\n",
    "| tip_amount | Сумма чаевых - Это поле автоматически заполняется для чаевых по кредитной карте. Чаевые наличными не учитываются. |\n",
    "| tolls_amount | Общая сумма всех дорожных сборов, оплаченных в поездке. |\n",
    "| total_amount | Общая сумма, взимаемая с пассажиров. Не включает денежные чаевые. |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вспомним схему данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- VendorID: integer (nullable = true)\n",
      " |-- passenger_count: integer (nullable = true)\n",
      " |-- trip_distance: float (nullable = true)\n",
      " |-- RateCodeID: integer (nullable = true)\n",
      " |-- store_and_fwd_flag: boolean (nullable = true)\n",
      " |-- payment_type: integer (nullable = true)\n",
      " |-- fare_amount: float (nullable = true)\n",
      " |-- extra: float (nullable = true)\n",
      " |-- tip_amount: float (nullable = true)\n",
      " |-- tolls_amount: float (nullable = true)\n",
      " |-- total_amount: float (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вычислим количество строк в датафрейме."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6036111"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Постановка задачи\n",
    "\n",
    "Для датасета, заданного представленными колонками, требуется построить модель **Random Forest Classifier** для оценки факта того, **много или мало будет пассажиров в данной поездке**, по всем остальным признакам.\n",
    "\n",
    "Для этого бинаризируем столбец passenger_count по границе 5. 0-4 пассажиров будет 0 (мало), а 5-9 пассажиров будет 1 (много)\n",
    "\n",
    "Для оценки качества обучения следует использовать метрики `Precision` и `Recall`. Оценить максимально возможное значение **точности** при полноте не менее 60%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Подготовка признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(\"trip_distance\", F.col(\"trip_distance\").cast(DoubleType()))\n",
    "df = df.withColumn(\"fare_amount\", F.col(\"fare_amount\").cast(DoubleType()))\n",
    "df = df.withColumn(\"total_amount\", F.col(\"total_amount\").cast(DoubleType()))\n",
    "df = df.withColumn(\"tip_amount\", F.col(\"tip_amount\").cast(DoubleType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- VendorID: integer (nullable = true)\n",
      " |-- passenger_count: integer (nullable = true)\n",
      " |-- trip_distance: double (nullable = true)\n",
      " |-- RateCodeID: integer (nullable = true)\n",
      " |-- store_and_fwd_flag: boolean (nullable = true)\n",
      " |-- payment_type: integer (nullable = true)\n",
      " |-- fare_amount: double (nullable = true)\n",
      " |-- extra: float (nullable = true)\n",
      " |-- tip_amount: double (nullable = true)\n",
      " |-- tolls_amount: float (nullable = true)\n",
      " |-- total_amount: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Bucketizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(\"passenger_count\", F.col(\"passenger_count\").cast(DoubleType()))\n",
    "splits = [-float(\"inf\"), 5.0, float(\"inf\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.drop('passenger_count_binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/11/17 20:18:55 WARN YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "[Stage 0:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------------+------------------+----------+------------------+------------+-----------+-----+------------------+------------+------------------+----------------------+\n",
      "|VendorID|passenger_count|     trip_distance|RateCodeID|store_and_fwd_flag|payment_type|fare_amount|extra|        tip_amount|tolls_amount|      total_amount|passenger_count_binary|\n",
      "+--------+---------------+------------------+----------+------------------+------------+-----------+-----+------------------+------------+------------------+----------------------+\n",
      "|       2|            1.0|2.7200000286102295|         1|             false|           1|       12.5|  0.5|              3.25|         0.0|17.049999237060547|                   0.0|\n",
      "|       2|            1.0| 1.590000033378601|         1|             false|           1|        7.5|  0.5| 1.600000023841858|         0.0|10.399999618530273|                   0.0|\n",
      "|       2|            1.0|0.8999999761581421|         1|             false|           1|        6.0|  0.5|               1.0|         0.0| 8.300000190734863|                   0.0|\n",
      "|       2|            1.0|1.9600000381469727|         1|             false|           1|        9.5|  0.5|               2.0|         0.0|12.800000190734863|                   0.0|\n",
      "|       2|            3.0| 8.930000305175781|         1|             false|           1|       32.0|  0.5|               0.0|         0.0| 33.29999923706055|                   0.0|\n",
      "|       2|            1.0| 2.450000047683716|         1|             false|           1|       13.0|  0.5| 2.700000047683716|         0.0|              17.0|                   0.0|\n",
      "|       2|            2.0| 2.630000114440918|         1|             false|           1|       11.5|  0.5|2.4000000953674316|         0.0|15.199999809265137|                   0.0|\n",
      "|       2|            1.0|1.1100000143051147|         1|             false|           1|        6.5|  0.5| 1.399999976158142|         0.0| 9.199999809265137|                   0.0|\n",
      "|       2|            1.0|1.7000000476837158|         1|             false|           1|        8.5|  0.5|               5.0|         0.0|14.800000190734863|                   0.0|\n",
      "|       2|            4.0|0.9300000071525574|         1|             false|           2|        6.5|  0.5|               0.0|         0.0| 7.800000190734863|                   0.0|\n",
      "|       2|            1.0|1.3899999856948853|         1|             false|           2|        7.0|  0.5|               0.0|         0.0| 8.300000190734863|                   0.0|\n",
      "|       2|            5.0|               2.0|         1|             false|           2|       10.0|  0.5|               0.0|         0.0|11.300000190734863|                   1.0|\n",
      "|       2|            1.0|1.2999999523162842|         1|             false|           2|        7.0|  0.5|               0.0|         0.0| 8.300000190734863|                   0.0|\n",
      "|       2|            1.0| 17.43000030517578|         1|             false|           2|       49.0|  0.5|               0.0|         0.0| 50.29999923706055|                   0.0|\n",
      "|       1|            4.0|               3.5|         1|             false|           2|       15.0|  1.0|               0.0|         0.0|16.799999237060547|                   0.0|\n",
      "|       1|            1.0| 2.200000047683716|         1|             false|           1|       12.5|  1.0| 2.859999895095825|         0.0| 17.15999984741211|                   0.0|\n",
      "|       1|            1.0|               0.0|         1|             false|           2|        7.0|  1.0|               0.0|         0.0| 8.800000190734863|                   0.0|\n",
      "|       1|            1.0|0.6000000238418579|         1|             false|           1|        4.0|  1.0| 1.159999966621399|         0.0| 6.960000038146973|                   0.0|\n",
      "|       1|            1.0| 2.200000047683716|         1|             false|           2|       11.5|  1.0|               0.0|         0.0|13.300000190734863|                   0.0|\n",
      "|       1|            1.0|               1.5|         1|             false|           2|        8.0|  1.0|               0.0|         0.0| 9.800000190734863|                   0.0|\n",
      "+--------+---------------+------------------+----------+------------------+------------+-----------+-----+------------------+------------+------------------+----------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "bucketizer = Bucketizer(splits=splits, inputCol=\"passenger_count\", outputCol=\"passenger_count_binary\")\n",
    "df = bucketizer.transform(df)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(\"passenger_count_binary\", F.col(\"passenger_count_binary\").cast(IntegerType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------------+------------------+----------+------------------+------------+-----------+-----+------------------+------------+------------------+----------------------+\n",
      "|VendorID|passenger_count|     trip_distance|RateCodeID|store_and_fwd_flag|payment_type|fare_amount|extra|        tip_amount|tolls_amount|      total_amount|passenger_count_binary|\n",
      "+--------+---------------+------------------+----------+------------------+------------+-----------+-----+------------------+------------+------------------+----------------------+\n",
      "|       2|            1.0|2.7200000286102295|         1|             false|           1|       12.5|  0.5|              3.25|         0.0|17.049999237060547|                     0|\n",
      "|       2|            1.0| 1.590000033378601|         1|             false|           1|        7.5|  0.5| 1.600000023841858|         0.0|10.399999618530273|                     0|\n",
      "|       2|            1.0|0.8999999761581421|         1|             false|           1|        6.0|  0.5|               1.0|         0.0| 8.300000190734863|                     0|\n",
      "|       2|            1.0|1.9600000381469727|         1|             false|           1|        9.5|  0.5|               2.0|         0.0|12.800000190734863|                     0|\n",
      "|       2|            3.0| 8.930000305175781|         1|             false|           1|       32.0|  0.5|               0.0|         0.0| 33.29999923706055|                     0|\n",
      "|       2|            1.0| 2.450000047683716|         1|             false|           1|       13.0|  0.5| 2.700000047683716|         0.0|              17.0|                     0|\n",
      "|       2|            2.0| 2.630000114440918|         1|             false|           1|       11.5|  0.5|2.4000000953674316|         0.0|15.199999809265137|                     0|\n",
      "|       2|            1.0|1.1100000143051147|         1|             false|           1|        6.5|  0.5| 1.399999976158142|         0.0| 9.199999809265137|                     0|\n",
      "|       2|            1.0|1.7000000476837158|         1|             false|           1|        8.5|  0.5|               5.0|         0.0|14.800000190734863|                     0|\n",
      "|       2|            4.0|0.9300000071525574|         1|             false|           2|        6.5|  0.5|               0.0|         0.0| 7.800000190734863|                     0|\n",
      "|       2|            1.0|1.3899999856948853|         1|             false|           2|        7.0|  0.5|               0.0|         0.0| 8.300000190734863|                     0|\n",
      "|       2|            5.0|               2.0|         1|             false|           2|       10.0|  0.5|               0.0|         0.0|11.300000190734863|                     1|\n",
      "|       2|            1.0|1.2999999523162842|         1|             false|           2|        7.0|  0.5|               0.0|         0.0| 8.300000190734863|                     0|\n",
      "|       2|            1.0| 17.43000030517578|         1|             false|           2|       49.0|  0.5|               0.0|         0.0| 50.29999923706055|                     0|\n",
      "|       1|            4.0|               3.5|         1|             false|           2|       15.0|  1.0|               0.0|         0.0|16.799999237060547|                     0|\n",
      "|       1|            1.0| 2.200000047683716|         1|             false|           1|       12.5|  1.0| 2.859999895095825|         0.0| 17.15999984741211|                     0|\n",
      "|       1|            1.0|               0.0|         1|             false|           2|        7.0|  1.0|               0.0|         0.0| 8.800000190734863|                     0|\n",
      "|       1|            1.0|0.6000000238418579|         1|             false|           1|        4.0|  1.0| 1.159999966621399|         0.0| 6.960000038146973|                     0|\n",
      "|       1|            1.0| 2.200000047683716|         1|             false|           2|       11.5|  1.0|               0.0|         0.0|13.300000190734863|                     0|\n",
      "|       1|            1.0|               1.5|         1|             false|           2|        8.0|  1.0|               0.0|         0.0| 9.800000190734863|                     0|\n",
      "+--------+---------------+------------------+----------+------------------+------------+-----------+-----+------------------+------------+------------------+----------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Выберем нужные столбцы\n",
    "feature_columns = [\"VendorID\", \"RateCodeID\", \"payment_type\", \"store_and_fwd_flag\", \"fare_amount\", \n",
    "                   \"extra\", \"tip_amount\", \"tolls_amount\", \"total_amount\", \"trip_distance\"]\n",
    "\n",
    "assembler = VectorAssembler(inputCols=feature_columns, outputCol='features')\n",
    "\n",
    "# Преобразуем данные\n",
    "data_transformed = assembler.transform(df)\n",
    "\n",
    "# Подготовим данные для модели\n",
    "final_data = data_transformed.select('features', 'passenger_count_binary')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- features: vector (nullable = true)\n",
      " |-- passenger_count_binary: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_data.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выполним разделение датасета на обучающую и тестовую выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = final_data.randomSplit([0.8, 0.2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Закешируем сформированные датафреймы и проверим их объем."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size: 4829702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 6:=============================>                             (1 + 1) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test  dataset size: 1206409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "train_data = train_data.cache()\n",
    "test_data = test_data.cache()\n",
    "\n",
    "print(f\"Train dataset size: {train_data.count()}\")\n",
    "print(f\"Test  dataset size: {test_data.count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Обучение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(labelCol=\"passenger_count_binary\", featuresCol=\"features\", numTrees=100)\n",
    "cv_model = rf.fit(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Анализ обученной модели\n",
    "\n",
    "Рассчитаем метрики на тестовом датасете."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+----------+\n",
      "|passenger_count_binary|prediction|\n",
      "+----------------------+----------+\n",
      "|                     0|       0.0|\n",
      "|                     0|       0.0|\n",
      "|                     0|       0.0|\n",
      "|                     0|       0.0|\n",
      "|                     0|       0.0|\n",
      "|                     0|       0.0|\n",
      "|                     0|       0.0|\n",
      "|                     0|       0.0|\n",
      "|                     0|       0.0|\n",
      "|                     0|       0.0|\n",
      "|                     0|       0.0|\n",
      "|                     0|       0.0|\n",
      "|                     0|       0.0|\n",
      "|                     0|       0.0|\n",
      "|                     0|       0.0|\n",
      "|                     0|       0.0|\n",
      "|                     0|       0.0|\n",
      "|                     0|       0.0|\n",
      "|                     0|       0.0|\n",
      "|                     0|       0.0|\n",
      "+----------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Делаем предсказания на тестовой выборк\n",
    "predictions = cv_model.transform(test_data)\n",
    "\n",
    "# Отображаем предсказания\n",
    "predictions.select(\"passenger_count_binary\", \"prediction\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 34:=============================>                            (1 + 1) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9106646253467937\n",
      "F1 Score: 0.8680854283440694\n",
      "Precision: 0.8293100598580161\n",
      "Recall: 0.9106646253467937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Оценка модели с помощью метрик\n",
    "evaluator_accuracy = MulticlassClassificationEvaluator(labelCol=\"passenger_count_binary\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator_accuracy.evaluate(predictions)\n",
    "\n",
    "evaluator_f1 = MulticlassClassificationEvaluator(labelCol=\"passenger_count_binary\", predictionCol=\"prediction\", metricName=\"f1\")\n",
    "f1_score = evaluator_f1.evaluate(predictions)\n",
    "\n",
    "evaluator_precision = MulticlassClassificationEvaluator(labelCol=\"passenger_count_binary\", predictionCol=\"prediction\", metricName=\"weightedPrecision\")\n",
    "precision = evaluator_precision.evaluate(predictions)\n",
    "\n",
    "evaluator_recall = MulticlassClassificationEvaluator(labelCol=\"passenger_count_binary\", predictionCol=\"prediction\", metricName=\"weightedRecall\")\n",
    "recall = evaluator_recall.evaluate(predictions)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"F1 Score: {f1_score}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Precision (Точность):\n",
    "   - Определяется как отношение истинно положительных результатов (True Positives, TP) к сумме истинно положительных и ложноположительных (False Positives, FP).\n",
    "   - Эта метрика показывает, какую долю положительных предсказаний модель сделала правильно. Высокое значение precision означает, что модель не часто ошибается, когда предсказывает положительный класс.\n",
    "\n",
    "2. Recall (Полнота):\n",
    "   - Определяется как отношение истинно положительных результатов (TP) к сумме истинно положительных и ложноотрицательных (False Negatives, FN).\n",
    "   - Recall показывает, какую долю реальных положительных примеров модель смогла обнаружить. Высокое значение recall означает, что модель мало упускает положительных примеров.\n",
    "\n",
    "3. F1 Score:\n",
    "   - Это среднее гармоническое между precision и recall.\n",
    "   - F1 Score учитывает как false positives, так и false negatives, и является более сбалансированной метрикой, чем просто accuracy, особенно в случаях, когда классы несбалансированы. Высокое значение F1 Score указывает на то, что модель хорошо справляется с задачей обнаружения положительных классов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Получаем датасет предсказаний\n",
    "test_df_predictions = cv_model.transform(test_data)\n",
    "\n",
    "# Извлекаем список колонок, устанавливаем цену на последнее место\n",
    "right_columns_order = test_df_predictions.columns\n",
    "right_columns_order.remove(\"passenger_count_binary\")\n",
    "right_columns_order.append(\"passenger_count_binary\")\n",
    "\n",
    "# Изменяем последовательность колонок и выводим датафрейм\n",
    "test_df_predictions = test_df_predictions.select(*right_columns_order)\n",
    "test_df_predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Сохранение модели\n",
    "\n",
    "Зададим директорию студента в `HDFS`, в которой будет сохранена обученная модель."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_hdfs_folder = \"gysynin_dmitry_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 42:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Модель успешно сохранена в \"hdfs:///user/user0/gysynin_dmitry_data/models/rf-model-2\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Получаем имя пользователя\n",
    "user_name = os.getenv(\"USER\")\n",
    "\n",
    "# Путь модели в HDFS\n",
    "model_hdfs_path = f\"hdfs:///user/{user_name}/{student_hdfs_folder}/models/rf-model-2\"\n",
    "\n",
    "# Сохраняем модель конвейера в HDFS\n",
    "try:\n",
    "    cv_model.save(model_hdfs_path)\n",
    "    print(f\"Модель успешно сохранена в \\\"{model_hdfs_path}\\\"\")\n",
    "except Exception as e:\n",
    "    print(f\"Ошибка при сохранении модели: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Не забываем завершать `Spark`-сессию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
